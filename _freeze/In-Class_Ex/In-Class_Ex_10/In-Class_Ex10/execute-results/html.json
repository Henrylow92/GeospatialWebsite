{
  "hash": "1c227feaa5d9da32d655cc5c9d6371b8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"In Class Exercise 10\"\nauthor: \"Henry Low\"\ndate: \"Nov 4 2024\"\ndate-modified: \"last-modified\"\nexecute:\n  evalu: true\n  echo: true\n  message: false\n  freeze: true\nformat: html\neditor: visual\n---\n\n\n\n# Setting Up\n\n## Load Packages\n\n\\-`sf` package to perform geospatial wrangling tasks \\\n-`SpatialAcc` package to model geographical accessibility tasks \\\n- `tmap` package for plotting tasks \\\n- `ggstatsplot` package for statistical analysis \\\n-`tidyverse` package for reading csv files, dataframe processing tasks \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidyverse, sf, tmap, httr, performance)\n```\n:::\n\n\n\n## Importing Data\n\nThis will allow us to do the geocoding.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load resale data\nresale <- read_csv(\"data/aspatial/resale.csv\") %>%\n  filter(month >= \"2023-01\" & month <= \"2024-09\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 192234 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): month, town, flat_type, block, street_name, storey_range, flat_mode...\ndbl (3): floor_area_sqm, lease_commence_date, resale_price\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\n# Preprocess data\ncondo_resale <- resale %>%\n  mutate(address = paste(block,street_name)) %>%\n  mutate(remaining_lease_yr = as.integer(\n    str_sub(remaining_lease, 0, 2)))%>%\n  mutate(remaining_lease_mth = as.integer(\n    str_sub(remaining_lease, 9, 11)))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npostcode <- unique(condo_resale$`Postal Code`)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nurl <- \"https://onemap.gov.sg/api/common/elastic/search\"\nfound <- data.frame()\nnot_found <- data.frame()\n\nfor (postcode in postcode){\n  query <- list('searchVal'=postcode, 'returnGeom'='Y', \n                'getAddrDetails'='Y', 'pageNum'='1')\n  res <- GET(url, query=query)\n  if ((content(res)$found)!=0){\n    found <- rbind(found, data.frame(content(res))[4:13])\n  } else {not_found = data.frame(postcode)\n  }\n}\n```\n:::\n\n\n\n## Other Tips\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load in Thailand data\nprov_sf <- st_read(dsn = \" \", layers = \"\") %>%\n  st_transform()\n```\n:::\n\n\n\nFirst, convert multipolygons into individual polygons. Area is also calculated for each polygons\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsf_polygon <- prow_sf %>%\n  st_cast(\"POLYGON\") %>%\n  mutate(area = st_area(.))\n```\n:::\n\n\n\nThe data is then grouped by unique name and the largest polygon by area is selected.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprov_cleaned <- sf_polygon %>%\n  group_by(ADM1_EN) %>%\n  filter(area == max(area)) %>%\n  ungroup() %>%\n  select(-area) %>%\n  select(ADM1_EN)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntm_shape(prov_cleaned) %>%\n  tm_polygons()\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}