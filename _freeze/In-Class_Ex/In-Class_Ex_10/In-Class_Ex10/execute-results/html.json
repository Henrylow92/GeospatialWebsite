{
  "hash": "5c164b393fc29ab4f8f0adb79800ad46",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"In Class Exercise 10\"\nauthor: \"Henry Low\"\ndate: \"Nov 4 2024\"\ndate-modified: \"last-modified\"\nexecute:\n  evalu: true\n  echo: true\n  message: false\n  freeze: true\nformat: html\neditor: visual\n---\n\n\n\n# Setting Up\n\n## Load Packages\n\n\\-`sf` package to perform geospatial wrangling tasks \\\n-`httr` package to make api requests \\\n- `tmap` package for plotting tasks \\\n- `performance` package for model performance \\\n-`tidyverse` package for reading csv files, dataframe processing tasks \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidyverse, sf, tmap, httr, performance)\n```\n:::\n\n\n\n## Importing Data\n\nIf there are multiple files in a specified folder, I can use the following to import them (assuming they have the same pattern) and append them into a tibble dataframe.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load data\nfolder_path <- \"data/aspatial\"\nfile_list <- list.files(path = folder_path, \n                        pattern = \"^realis.*\\\\.csv$\", \n                        full.names = TRUE)\n\nrealis_data <- file_list %>%\n  map_dfr(read_csv)\n\n# Create condo resale data\ncondo_resale <- realis_data %>%\n  mutate(`Sale Date` = dmy(`Sale Date`)) %>%\n  filter(`Type of Sale` == \"Resale\" &\n           `Property Type` == \"Condominium\")\n```\n:::\n\n\n\nDue to the lack of data I will load in the resale data instead.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load resale data\nresale <- read_rds(\"data/resale_sf.rds\") %>%\n  filter(month == \"2024-09\") %>%\n  st_drop_geometry()\n\n# Preprocess data\ncondo_resale <- resale %>%\n  mutate(address = paste(block,street_name)) %>%\n  mutate(remaining_lease_yr = as.integer(\n    str_sub(remaining_lease, 0, 2)))%>%\n  mutate(remaining_lease_mth = as.integer(\n    str_sub(remaining_lease, 9, 11))) %>%\n  filter(postal != \"NIL\") %>%\n  rename(`Postal Code` = postal)\n```\n:::\n\n\n\n## Data Wrangling\n\nI need to get a unique list of postal codes which will be run by the function to get the geocoding\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get unique postal codes\npostcode <- unique(condo_resale$`Postal Code`)\n```\n:::\n\n\n\nWith the list of postal code, I can make GET requests iteratively to the onemap api.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl <- \"https://onemap.gov.sg/api/common/elastic/search\"\nfound <- data.frame()\nnot_found <- data.frame()\n\nfor (postcode in postcode){\n  query <- list('searchVal'=postcode, 'returnGeom'='Y', \n                'getAddrDetails'='Y', 'pageNum'='1')\n  res <- GET(url, query=query)\n  if ((content(res)$found)!=0){\n    found <- rbind(found, data.frame(content(res))[4:13])\n  } else {not_found = data.frame(postcode)\n  }\n}\n```\n:::\n\n\n\nThe output will be saved for easy retrieval.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# # Save output\n# write_rds(found, \"data/found.rds\")\n# write_rds(not_found, \"data/not_found.rds\")\n\n# Load output\nfound <- read_rds(\"data/found.rds\")\nnot_found <- read_rds(\"data/not_found.rds\")\n```\n:::\n\n\n\nAfter getting the results, some tidying is required. The clean output is then appended to the resale data and converted into a sf dataframe with `st_as_sf()` from `sf` package.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Process the results\nfound <- found %>%\n  select(c(6:8)) %>%\n  rename(POSTAL = `results.POSTAL`,\n         XCOORD = `results.X`,\n         YCOORD = `results.Y`)\n\n# Append results to aspatial data\ncondo_resale_geocoded = left_join(\n  condo_resale, found, \n  by = c('Postal Code' = 'POSTAL')) %>%\n  filter()\n\n\n# Convert the dataframe to sf dataframe\ncondo_resale_sf <- st_as_sf(condo_resale_geocoded, \n                            coords = c(\"XCOORD\",\n                                       \"YCOORD\"),\n                            crs=3414)\n```\n:::\n\n\nSince overlapping points may cause issues, I will need to check if there are any.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check for overlapping point\noverlapping_points <- condo_resale_sf %>%\n  mutate(overlap = lengths(st_equals(., .)) > 1)\n```\n:::\n\n\n\nIf there are any overlapping points, `st_jitter()` with 2 metres will be used.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Jitter\ncondo_resale_sf <- condo_resale_sf %>%\n  st_jitter(amount = 2)\n```\n:::\n\n\n\n\n## Other Tips\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load in Thailand data\nprov_sf <- st_read(dsn = \"data/tha_adm_rtsd_itos_20210121_shp/\", layer = \"tha_admbnda_adm1_rtsd_20220121\") %>%\n  st_transform(crs = 32647) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\Users\\Henry\\Desktop\\SMU Masters\\2024-2025 T1\\Geospatial Analytics & Applications\\Project\\GeospatialWebsite\\In-Class_Ex\\In-Class_Ex_10\\data\\tha_adm_rtsd_itos_20210121_shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n:::\n\n\n\nFirst, convert multipolygons into individual polygons. Area is also calculated for each polygons\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsf_polygon <- prov_sf %>%\n  st_cast(\"POLYGON\") %>%\n  mutate(area = st_area(.))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in st_cast.sf(., \"POLYGON\"): repeating attributes for all\nsub-geometries for which they may not be constant\n```\n\n\n:::\n:::\n\n\n\nThe data is then grouped by unique name and the largest polygon by area is selected.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprov_cleaned <- sf_polygon %>%\n  group_by(ADM1_EN) %>%\n  filter(area == max(area)) %>%\n  ungroup() %>%\n  select(-area) %>%\n  select(ADM1_EN)\n```\n:::\n\n\n\nAfter cleaning it, I can visualize it with tm_shape\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\ntmap mode set to plotting\n```\n\n\n:::\n\n```{.r .cell-code}\ntm_shape(prov_cleaned) +\n  tm_polygons()\n```\n\n::: {.cell-output-display}\n![](In-Class_Ex10_files/figure-html/unnamed-chunk-13-1.png){width=1152}\n:::\n:::\n",
    "supporting": [
      "In-Class_Ex10_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}