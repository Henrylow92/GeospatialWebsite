---
title: "Take Home Exercise 01"
author: "Henry Low"
date: "Sep 2 2024"
date-modified: "last-modified"
execute:
  evalu: true
  echo: true
  message: false
  freeze: true
format: html
editor: visual
---

# Background

Road traffic accidents cause 1.19 million deaths and 20 to 50 million injuries annually, with most fatalities occurring in low- and middle-income countries (World Health Organisation (WHO)). Road traffic injuries are the leading cause of death for individuals aged 5–29 and place a heavy economic burden on nations, costing up to 3% of GDP. Thailand has some of the deadliest roads globally, with about 20,000 fatalities annually. From 2014 to 2021, accidents rose, especially on national highways, with black spots frequently found on straight roads and intersections.

# Objectives

Focusing in the Bangkok Metropolitan Region (BMR), Spatial Point Patterns Analysis (SPPA) will be used to explore and identify factors influencing road traffic accidents. Such facts are mainly behavioral and environmental, with this exercise aiming to incorporate temporal factors as well. Specific objectives are as follows:\
- To visualize the spatio-temporal dynamics of road traffic accidents in BMR using appropriate statistical graphics and geovisualization methods.\
- To conduct detailed spatial analysis of road traffic accidents using appropriate Network Spatial Point Patterns Analysis methods.\
- To conduct detailed spatio-temporal analysis of road traffic accidents using appropriate Temporal Network Spatial Point Patterns Analysis methods.

# Study Area

The study area will be Bangkok Metropolitan Region, which is defined [here](https://en.wikipedia.org/wiki/Bangkok_Metropolitan_Region).

# Data Sources

*(saved under 'data' folder)*\
[Thailand Road Accident 2019-2022](https://www.kaggle.com/datasets/thaweewatboy/thailand-road-accident-2019-2022) from Kaggle\
[Thailand Roads (OpenStreetMap Export) from HDX](https://s3.dualstack.us-east-1.amazonaws.com/production-raw-data-api/ISO3/THA/roads/lines/hotosm_tha_roads_lines_shp.zip)\
[Thailand - Subnational Administrative Boundaries from HDX](https://data.humdata.org/dataset/cod-ab-tha?)...[Click here to download here](https://data.humdata.org/dataset/d24bdc45-eb4c-4e3d-8b16-44db02667c27/resource/d0c722ff-6939-4423-ac0d-6501830b1759/download/tha_adm_rtsd_itos_20210121_shp.zip)

# 1. Setting Up

## 1.1 Loading R Packages

I will be using the following R packages:\
-`sf` package to perform geospatial wrangling tasks \
- `spNetwork` package to perform network kernel density estimation (NKDE) and temporal network kernel density estimation \
- `tidyverse` package for reading csv files, dataframe processing tasks \
- `tmap` package for plotting tasks \

```{r}
pacman::p_load(tidyverse, spatstat, sf, spNetwork, tmap)
```

## 1.2 Loading Datasets

### 1.2.1 Thailand Road Accidents Data

```{r}
# Load 2019-2020 Road Accidents Data
ra_tbl <- read_csv('data/thai_road_accident_2019_2022.csv')
# Check data
glimpse(ra_tbl)
```

### 1.2.2 Thailand Openstreet Map Data

```{r}
# Load Thailand Roads from Openstreet Map
th_road <- st_read(dsn = "data/hotosm_tha_roads_lines_shp/", layer = "hotosm_tha_roads_lines_shp") 
```

```{r}
# Check data
# glimpse(th_road)
head(th_road, n=5)
```

### 1.2.3 Thailand Subnational Administrative Boundaries

Based on the description from HDX, there are a few administrative boundaries:\
- Level 0: Country\
- Level 1: Province\
- Level 2: District\
- Level 3: Sub-District, Tambon

While the dataset contains other `shp` files, the focus will be on those levels.

::: panel-tabset
# Level 0

```{r}
# Load Thailand Country from HDX
th_bound_l0 <- st_read(dsn = "data/tha_adm_rtsd_itos_20210121_shp/", layer = "tha_admbnda_adm0_rtsd_20220121")
glimpse(th_bound_l0)

# Visualize the boundaries
plot(st_geometry(th_bound_l0))
```

# Level 1

```{r}
# Load Thailand Province from HDX
th_bound_l1 <- st_read(dsn = "data/tha_adm_rtsd_itos_20210121_shp/", layer = "tha_admbnda_adm1_rtsd_20220121")
glimpse(th_bound_l1)

# Visualize the boundaries
plot(st_geometry(th_bound_l1))
```

# Level 2

```{r}
# Load Thailand Province from HDX
th_bound_l2 <- st_read(dsn = "data/tha_adm_rtsd_itos_20210121_shp/", layer = "tha_admbnda_adm2_rtsd_20220121") 
glimpse(th_bound_l2)

# Visualize the boundaries
plot(st_geometry(th_bound_l2))
```

# Level 3

```{r}
# Load Thailand Province from HDX
th_bound_l3 <- st_read(dsn = "data/tha_adm_rtsd_itos_20210121_shp/", layer = "tha_admbnda_adm3_rtsd_20220121") 
glimpse(th_bound_l3)

# Visualize the boundaries
plot(st_geometry(th_bound_l3))
```
:::

### 1.2.4 Basic Preprocessing

From a quick look of the various datasets, it is clear that preprocessing is required in order to filter the datasets to:\
1. Focus on the study area (Bangkok Metropolitan Region)\
2. Work with smaller data to better manage R session memory handling

Other geospatial preprocessing steps will also be taken accordingly. Once done, these datasets will be saved as RDS files for easy retrieval.

#### 1.2.4.1 Processing Thailand Road Accident

The Thailand road accident dataset will be processed to: - remove blanks/na from longitude/latitude (mitigate errors when converting into sf object) - filtered to Bangkok Metropolitan Region - convert tibble dataframe to sf dataframe - project to Thailand coordinate reference system for alignment and visualization

```{r}
# Transform Thailand Road Accident data
ra_tbl_flt <- ra_tbl %>%
  filter(!is.na(longitude) & longitude != "", !is.na(latitude) & latitude != "") %>%
  filter(province_en %in% c("Bangkok", "Nonthaburi", "Pathum Thani", 
                              "Samut Prakan", "Samut Sakhon", "Nakhon Pathom")) %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>%
  st_transform(crs = 32647)

# Check for duplicates
any(duplicated(st_coordinates(ra_tbl_flt)))
```
Since there are duplicates, as this may affect further analysis, `st_jitter` of sf will be used

```{r}
ra_tbl_flt_jittered <- st_jitter(ra_tbl_flt, amount = 0.1)
```


The processed data is then exported as RDS.

```{r}
# Export to processed sub-folder as RDS
write_rds(ra_tbl_flt_jittered, 'data/processed/th_acc.rds')
```

#### 1.2.4.2 Processing Thailand Subnational Administrative Boundaries

While level 1 was sufficient to filter the boundary to the study area, level 3 was selected for the flexibility purposes.

The level 3 Thailand Subnational Administrative Boundaries will be processed based to: - filtered to Bangkok Metropolitan Region - project to Thailand coordinate reference system for alignment and visualization

```{r}
# Filter Thai boundary for only Bangkok Metropolitan Region
th_bound_l3_flt <- th_bound_l3 %>%
  filter(ADM1_EN %in% c("Bangkok", "Nonthaburi", "Pathum Thani", 
                              "Samut Prakan", "Samut Sakhon", "Nakhon Pathom"))%>%
  st_transform(crs = 32647) 

glimpse(th_bound_l3_flt)
```

The processed data is again exported as RDS.

```{r}
# Export to processed sub-folder as RDS
write_rds(th_bound_l3_flt, 'data/processed/th_bound_l3.rds')
```

#### 1.2.4.1 Processing Thailand Openstreet Map Data

Given the large openstreet map dataset (\~2.7m objects), the dataset needs to be filtered prior to performing `st_intersects`.\
This will be done by selecting the relevant highway attributes. Relevant highway attributes are defined following the [default access restrictions](https://wiki.openstreetmap.org/wiki/WikiProject_Thailand#Default_Access_Restrictions) based on the Road Traffic Act, 1979 for various different vehicle types.

```{r}
# Check types of highway in Openstreet Map data
table(ra_tbl_flt$vehicle_type)
```

```{r}
# Check types of highway in Openstreet Map data
table(th_road$highway)
```

Given that accidents involving pedestrian and bicycle etc are proportionately smaller than those involving motorcar and motorcycle, the openstreet map data will be filtered to include relevant highway attribute for the latter vehicle types. Residental is additionally excluded for computation efficiency (large number of residential objects) and the less influential nature of the attribute (road within a residential area that gives the public access to one or multiple residences).

```{r}
# Filter Thai Openstreet Map data by highway types 
th_road_flt <- th_road %>%
  filter(highway %in% c('motorway', 'trunk', 'primary', 'secondary', 'tertiary', 'unclassified',  # Roads
                        'motorway_link', 'trunk_link', 'primary_link', 'secondary_link', 'tertiary_link',  # Link Roads
                        'living_street', 'road', 'path'
                        ) 
         ) %>%
  st_set_crs(., 4326) %>%
  st_transform(crs = 32647) 
glimpse(th_road_flt)
```

`st_intersects` is then used to return openstreet map objects that are within the study area.

```{r}
# # Use st_union to get overall study area boundary
th_bound_union <- th_bound_l3_flt %>%
  st_union()

# Use st_intersects to get roads within the study area
th_roads_intersects <- st_intersects(th_road_flt, th_bound_union)

# Get index mask of roads objects that intersects with study area 
roads_logical <- lengths(th_roads_intersects) > 0
# Filter openstreet map with the index mask
th_roads_bmr <- th_road_flt[roads_logical, ]


glimpse(th_roads_bmr)
```

::: panel-tabset
# Bangkok

```{r}
# Use st_union to get Bangkok boundary
bk_bound_union <- th_bound_l3_flt  %>%
  filter(ADM1_EN == "Bangkok") %>%
  st_union()

# Use st_intersects to get roads within Bangkok
bk_roads_intersects <- st_intersects(th_road_flt, bk_bound_union)

# Get index mask of roads objects that intersects with Bangkok
roads_logical_bk <- lengths(bk_roads_intersects) > 0
# Filter openstreet map with the index mask
th_roads_bk <- th_road_flt[roads_logical_bk, ]
```

# Nonthaburi

```{r}
# Use st_union to get Nonthaburi boundary
ntb_bound_union <- th_bound_l3_flt  %>%
  filter(ADM1_EN == "Nonthaburi") %>%
  st_union()

# Use st_intersects to get roads within Nonthaburi
ntb_roads_intersects <- st_intersects(th_road_flt, ntb_bound_union)

# Get index mask of roads objects that intersects with Nonthaburi
roads_logical_ntb <- lengths(ntb_roads_intersects) > 0
# Filter openstreet map with the index mask
th_roads_ntb <- th_road_flt[roads_logical_ntb, ]
```

# Pathum Thani

```{r}
# Use st_union to get Pathum Thani boundary
pt_bound_union <- th_bound_l3_flt  %>%
  filter(ADM1_EN == "Pathum Thani") %>%
  st_union()

# Use st_intersects to get roads within Pathum Thani
pt_roads_intersects <- st_intersects(th_road_flt, pt_bound_union)

# Get index mask of roads objects that intersects with Pathum Thani
roads_logical_pt <- lengths(pt_roads_intersects) > 0
# Filter openstreet map with the index mask
th_roads_pt <- th_road_flt[roads_logical_pt, ]
```

# Samut Prakan

```{r}
# Use st_union to get Samut Prakan boundary
sp_bound_union <- th_bound_l3_flt  %>%
  filter(ADM1_EN == "Samut Prakan") %>%
  st_union()

# Use st_intersects to get roads within Samut Prakan
sp_roads_intersects <- st_intersects(th_road_flt, sp_bound_union)

# Get index mask of roads objects that intersects with Samut Prakan
roads_logical_sp <- lengths(sp_roads_intersects) > 0
# Filter openstreet map with the index mask
th_roads_sp <- th_road_flt[roads_logical_sp, ]
```

# Samut Sakhon

```{r}
# Use st_union to get Samut Sakhon boundary
ss_bound_union <- th_bound_l3_flt  %>%
  filter(ADM1_EN == "Samut Sakhon") %>%
  st_union()

# Use st_intersects to get roads within Samut Sakhon
ss_roads_intersects <- st_intersects(th_road_flt, ss_bound_union)

# Get index mask of roads objects that intersects with Samut Sakhon
roads_logical_ss <- lengths(ss_roads_intersects) > 0
# Filter openstreet map with the index mask
th_roads_ss <- th_road_flt[roads_logical_ss, ]
```

# Nakhon Pathom

```{r}
# Use st_union to get Nakhon Pathom boundary
np_bound_union <- th_bound_l3_flt  %>%
  filter(ADM1_EN == "Nakhon Pathom") %>%
  st_union()

# Use st_intersects to get roads within Nakhon Pathom
np_roads_intersects <- st_intersects(th_road_flt, np_bound_union)

# Get index mask of roads objects that intersects with Nakhon Pathom
roads_logical_np <- lengths(np_roads_intersects) > 0
# Filter openstreet map with the index mask
th_roads_np <- th_road_flt[roads_logical_np, ]
```
:::

The processed openstreet map dataset is then exported in a similar fashion

```{r}
# Export to processed sub-folder as RDS
write_rds(th_roads_bmr, 'data/processed/th_osm.rds')

# Bangkok
write_rds(th_roads_bk, 'data/processed/th_osm_bk.rds')

# Nonthaburi
write_rds(th_roads_ntb, 'data/processed/th_osm_ntb.rds')

# Pathum Thani
write_rds(th_roads_pt, 'data/processed/th_osm_pt.rds')

# Samut Prakan
write_rds(th_roads_sp, 'data/processed/th_osm_sp.rds')

# Samut Sakhon
write_rds(th_roads_ss, 'data/processed/th_osm_ss.rds')

# Nakhon Pathom
write_rds(th_roads_np, 'data/processed/th_osm_np.rds')
```

# 2. Exploratory Data Analysis

## 2.1 Setting Up Environtment from Processed Datasets

First, we clear the R console, then load in the processed datasets. This is a suitable starting point to bypass the long loading/processing time of the various large datasets.

```{r}
# Clear R console
rm(list = ls(all.names = TRUE))

# Set seed to ensure reproducibility of all subsequent analysis
set.seed(42)
```

::: panel-tabset
# Accidents

```{r}
# Load data
ra_sf <- read_rds('data/processed/th_acc.rds')

# Check data
glimpse(ra_sf)

# Check crs
st_crs(ra_sf)
```

# Administrative Boundary

```{r}
# Load data
th_bound_sf <- read_rds('data/processed/th_bound_l3.rds')

# Check data
glimpse(th_bound_sf)

# Check crs
st_crs(th_bound_sf)
```

# Openstreet Map

```{r}
# Load data
th_osm_sf <- read_rds('data/processed/th_osm.rds') %>%
  st_cast("LINESTRING") # Cast as linestring as 

# Load other province data
bk_osm_sf <- read_rds('data/processed/th_osm_bk.rds') %>%
  st_cast("LINESTRING") # Cast as linestring as 
ntb_osm_sf <- read_rds('data/processed/th_osm_ntb.rds') %>%
  st_cast("LINESTRING") # Cast as linestring as 
pt_osm_sf <- read_rds('data/processed/th_osm_pt.rds') %>%
  st_cast("LINESTRING") # Cast as linestring as 
sp_osm_sf <- read_rds('data/processed/th_osm_sp.rds') %>%
  st_cast("LINESTRING") # Cast as linestring as 
ss_osm_sf <- read_rds('data/processed/th_osm_ss.rds') %>%
  st_cast("LINESTRING") # Cast as linestring as 
np_osm_sf <- read_rds('data/processed/th_osm_np.rds') %>%
  st_cast("LINESTRING") # Cast as linestring as 

# Check data
glimpse(th_osm_sf)

# Check crs
st_crs(th_osm_sf)
```
:::

## 2.2 Microsoft Power Bi Visualization

::: {style="position: relative; width: 100%; height: 0; padding-bottom: 56.25%;"}
<iframe title="Geospatial TakeHome Ex01" src="https://app.powerbi.com/view?r=eyJrIjoiZmMxMTNjMzEtYzhmMy00NTgwLTlkMjctODE1ZTA5YjNmN2E3IiwidCI6ImRmNGU4MzA3LWRjNjQtNDcyYS1iNGI1LWE2ZGQ2YmExMTU2NiIsImMiOjEwfQ%3D%3D" frameborder="0" allowFullScreen="true" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">

</iframe>
:::

adskl;adskl;asdkl;adskl;

## 2.3 Other Explorations

Lets try to find out the nearest neighbour distance of each accident. Knowing the distribution of these distances will be useful for determining the parameter values of subsequent analysis.

```{r}
# Simple EDA
table(th_osm_sf$highway)

ra_ppp <- as.ppp(ra_sf)

nn_distances <- nndist(ra_ppp)

hist(nn_distances, breaks = 100, main = "Nearest Neighbour Distance Distribution",
     xlab = "Distance (meters)")

summary(nn_distances)
```
Knowing that each accident occur very close to one another (median of ~13 meters), 

```{r}
ra_sf$Time <- as.POSIXct(ra_sf$incident_datetime, fomat = "%Y/%m/%d")
start <- as.POSIXct("2019/01/01", format = "%Y/%m/%d")
ra_sf$Time <- difftime(ra_sf$Time, start, units = "days")
ra_sf$Time <- as.numeric(ra_sf$Time)
ra_sf$Time_2019 <- as.POSIXct(paste("2019", format(ra_sf$incident_datetime, "%m/%d")), format = "%Y %m/%d ")
ra_sf$Time_2019 <- difftime(ra_sf$Time_2019, start, units = "days")
ra_sf$Time_2019 <- as.numeric(ra_sf$Time_2019)


years <- as.character(2019:2022)
months <- as.character(1:12)
months <- ifelse(nchar(months) == 1, paste0("0", months), months)
# Create a list of month start dates for each year
months_starts_labs <- outer(years, months, paste, sep = "/")
months_starts_labs <- as.vector(t(months_starts_labs))  # Flatten the matrix

# Convert month start labels to POSIXct and then to numeric days
months_starts_num <- as.POSIXct(paste0(months_starts_labs, "/01"), format = "%Y/%m/%d")
months_starts_num <- difftime(months_starts_num, start, units = "days")
months_starts_num <- as.numeric(months_starts_num)

# Create shorter month labels without the year
months_starts_labs_short <- gsub("^\\d{4}/", "", months_starts_labs)

# Plot the histogram using ggplot2
ggplot(ra_sf) + 
  geom_histogram(aes(x = Time), bins = 30, color = "white") + 
  scale_x_continuous(breaks = months_starts_num, labels = months_starts_labs_short) +
  labs(x = "Months", y = "Accidents") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


```{r}
w <- rep(1,nrow(ra_sf))
samples <- seq(0, max(ra_sf$Time), 0.5)

time_kernel_values <- data.frame(
  bw_10 = tkde(ra_sf$Time, w = w, samples = samples, bw = 10, kernel_name = "quartic"),
  bw_20 = tkde(ra_sf$Time, w = w, samples = samples, bw = 20, kernel_name = "quartic"),
  bw_30 = tkde(ra_sf$Time, w = w, samples = samples, bw = 30, kernel_name = "quartic"),
  bw_40 = tkde(ra_sf$Time, w = w, samples = samples, bw = 40, kernel_name = "quartic"),
  bw_50 = tkde(ra_sf$Time, w = w, samples = samples, bw = 50, kernel_name = "quartic"),
  bw_60 = tkde(ra_sf$Time, w = w, samples = samples, bw = 60, kernel_name = "quartic"),
  time = samples
)

df_time <- reshape2::melt(time_kernel_values,id.vars = "time")
df_time$variable <- as.factor(df_time$variable)

ggplot(data = df_time) + 
  geom_line(aes(x = time, y = value)) +
  scale_x_continuous(breaks = months_starts_num, labels = months_starts_labs) +
  facet_wrap(vars(variable), ncol=2, scales = "free") + 
  theme(axis.text = element_text(size = 5))
```

While interesting patterns can be observed across different temporal bandwidths, there are still. Let try to see the remove the year and view the temporal attribute as month of year instead.

```{r}
ra_sf$start_of_year <- as.POSIXct(paste0(format(ra_sf$incident_datetime, "%Y"), "-01-01"), format = "%Y-%m-%d")
ra_sf$days_since_start_of_year <- as.numeric(difftime(ra_sf$incident_datetime, ra_sf$start_of_year, units = "days"))

months <- as.character(1:12)
months <- ifelse(nchar(months)==1, paste0("0", months), months)
months_starts_labs <- paste("2019/",months,"/01", sep = "")
months_starts_num <- as.POSIXct(months_starts_labs, format = "%Y/%m/%d")
months_starts_num <- difftime(months_starts_num, start, units = "days")
months_starts_num <- as.numeric(months_starts_num)
months_starts_labs <- gsub("2019/", "", months_starts_labs, fixed = TRUE)

ggplot(ra_sf) + 
  geom_histogram(aes(x = Time_2019), bins = 30, color = "white") + 
  scale_x_continuous(breaks = months_starts_num, labels = months_starts_labs)
```

Now that the we are only looking at months of year, it is clear that there are some months (~April-May and ~October-November) that have more accidents.

```{r}
w <- rep(1,nrow(ra_sf))
samples <- seq(0, max(ra_sf$days_since_start_of_year), 0.5)

time_kernel_values <- data.frame(
  bw_10 = tkde(ra_sf$days_since_start_of_year, w = w, samples = samples, bw = 10, kernel_name = "quartic"),
  bw_20 = tkde(ra_sf$days_since_start_of_year, w = w, samples = samples, bw = 20, kernel_name = "quartic"),
  bw_30 = tkde(ra_sf$days_since_start_of_year, w = w, samples = samples, bw = 30, kernel_name = "quartic"),
  bw_40 = tkde(ra_sf$days_since_start_of_year, w = w, samples = samples, bw = 40, kernel_name = "quartic"),
  bw_50 = tkde(ra_sf$days_since_start_of_year, w = w, samples = samples, bw = 50, kernel_name = "quartic"),
  bw_60 = tkde(ra_sf$days_since_start_of_year, w = w, samples = samples, bw = 60, kernel_name = "quartic"),
  time = samples
)

df_time <- reshape2::melt(time_kernel_values,id.vars = "time")
df_time$variable <- as.factor(df_time$variable)

ggplot(data = df_time) + 
  geom_line(aes(x = time, y = value)) +
  scale_x_continuous(breaks = months_starts_num, labels = months_starts_labs) +
  facet_wrap(vars(variable), ncol=2, scales = "free") + 
  theme(axis.text = element_text(size = 5))
```

From this, we can clearly see that there might be a seasonal bimodal trend captured with a temporal bandwidth of 30-40 days.






adsjkladsljkadsjklasdjkl


It is important to note that given the context of the issue, it is not encouraged to perform any typical spatial point pattern analysis.

First-order spatial point pattern analysis such as kernel density estimation and nearest neighbours (i.e. Clark-Evans test) may give an indication of whether the events are clustered, regular or randomly occur, possibly highlighting potential accident hotspots. On the other hand second-order spatial point pattern analysis may illustrate spatial dependencies indicating underlying hazard. Nevertheless, techniques under both analysis are likely to be misleading as it will be heavily biased.

From the exploratory data analysis, it is clear that accidents are network constrained. This will induce misleading results as the above analysis techniques assume that events can occur throughout the study area. Therefore, density based analysis such as KDE will naturally cluster around roads, whereas second-order spatial point analysis such as the F-function will calculate the distribution of distances from random locations in the study area to the nearest point in the pattern (including locations impossible for road accident to occur).

Therefore, network spatial point pattern analysis will be the key analysis for this task.






# 3 Network Spatial Point Pattern Analysis

In network spatial point pattern analysis,

## 3.1 Network Kernel Density Estimation



## 3.1.1 Preparing objects required for performing NKDE

Before generating lixels with `lixelize_lines()` of spNetwork, we need to know what is the appropriate length of a lixel.

```{r}
# Check 
th_road_lengths <- st_length(th_osm_sf)
summary(th_road_lengths)
```

```{r}
# Plot histogram of road lengths
hist(th_road_lengths, breaks = 100, main = "Distribution of Road Segment Lengths",
     xlab = "Road Segment Length (meters)")
```

Based on the above, 200 meters will be selected as the lixel length, as it is more than most road segments (median 113 meters) and it is not too computationally intensive. The minimum lixel length in this case will be the default 1/10 of lixel length.

```{r}
# Create lixels
th_lixels <- lixelize_lines(th_osm_sf, 200)

# Create samples
th_samples <- lines_center(th_lixels) 
```

## 3.1.2 Bandwidth selction for performing NKDE

Main points of consideration for running a network KDE are:\
- Adaptive: False due to the computation load and also because the entire study area share a relatively similar network (urban throughout) with lesser accident variation across the network.\
- kernel: quartic as it provides a good balance between local and global estimation\
- method: simple as most accidents happen along the road rather than at intersections

With those in mind, bandwidth selection will be determined through `bw_cv_likelihood_calc` of spNetwork, using likelihood cross validation (aims to find a bandwidth that gives the most similar results when an event is removed). The bandwidth ranges from 25 to 425 based on the nearest neighbour analysis. 25 meters cover most distances between 2 accidents (median of 13 meters), and after 425 meters it is too wide.

```{r}
#| eval: false # eval: false
th_bws_selection_cv <- bw_cv_likelihood_calc(
  lines = th_osm_sf, 
  events = ra_sf,
  w = rep(1, nrow(ra_sf)),
  kernel_name = "quartic",
  bws = seq(25,425,50),
  method = "simple", 
  digits = 1, 
  tol = 0.1,
  grid_shape = c(5,5), 
  max_depth = 8,
  agg = 5, 
  sparse = TRUE, # Slower but require less memory
  verbose = TRUE)
```

CV results are exported for ease of rendering.

```{r}
# # Export output object and read it in to minimize rendering time
# write_rds(th_bws_selection_cv, 'data/output/th_bws_selection_cv.rds') # Uncomment when running the CV again

# Read in output object
th_bws_selection_cv <- read_rds('data/output/th_bws_selection_cv.rds')
```


```{r}
# Visualize CV Scores
plot(th_bws_selection_cv$bw, th_bws_selection_cv$cv_scores, 
     type = "o", col = "blue", xlab = "Bandwidth (bw)", ylab = "CV Scores",
     main = "CV Scores vs Bandwidth", pch = 19, lty = 1)
text(th_bws_selection_cv$bw, th_bws_selection_cv$cv_scores, 
     labels = round(th_bws_selection_cv$cv_scores, 0), pos = 3, cex = 0.8, col = "black")
grid()
```

With this in mind, 225 meters is selected as the bandwidth. Although the cross validation scores favor larger bandwidth, 225 is selected as a trade off between cv performance and potential overfitting. 

## 3.1.3 Performing NKDE

```{r}
#| eval: false # eval: false
future::plan(future::multisession(workers=8))
# Set global option for parallel-safe random number generation
options(future.seed = TRUE)

th_densities <- nkde.mc(th_osm_sf, 
                  events = ra_sf,
                  w = rep(1, nrow(ra_sf)),
                  samples = th_samples,
                  kernel_name = "quartic",
                  bw = 225, 
                  div= "bw", 
                  method = "simple", 
                  digits = 1, 
                  tol = 0.1,
                  grid_shape = c(5,5), 
                  max_depth = 8,
                  agg = 5, 
                  sparse = TRUE, # Slower but require less memory
                  verbose = FALSE)
```

Results are exported for ease of rendering.

```{r}
# # Export output object and read it in to minimize rendering time
# write_rds(th_densities, 'data/output/th_nkde_densities.rds') # Uncomment when running the NKDE again

# Read in output object
th_densities <- read_rds('data/output/th_nkde_densities.rds')

# Check density values
summary(th_densities)
```
Given the small values of the densities, slight scaling adjustments will be made to improve the readability after appending the results to the respective lixels and samples.

```{r}
# Append results to the sample and lixel
th_samples$density <- th_densities
th_lixels$density <- th_densities

# Rescale by 1e6
th_samples$density <- th_samples$density*1000000
th_lixels$density <- th_lixels$density*1000000
```

Due to the distribution of density having very small values, log transformation will be made onto the density to improve the contrast 

```{r, fig.width=12, fig.height=8}
# Log transform the density values (small offset to avoid log(0))
th_lixels$log_density <- log(th_lixels$density + 0.000001)

# Create overall TH boundary
th_bound_all <- th_bound_sf %>%
  st_union()

tmap_mode('plot')
tm_shape(th_lixels)+
  tm_lines(col="log_density", palette = 'YlOrRd', style = "cont") +
tm_shape(th_bound_all) +
  tm_borders()
```


While the plot is largely, it can be seen that there are some patches of roads with higher density, signifying potential hotspots for accidents.
```{r}
plot(st_geometry(th_bound_all))
```


## 3.2 Temporal Network Spatial Point Patterns Analysis



### 3.2.1 Bandwidth selction for performing TNKDE

```{r}
#| eval: false # eval: false
tnkde_cv_scores <- bw_tnkde_cv_likelihood_calc(
  bws_net = seq(200,2000, 100),
  bws_time = seq(10,100,10),
  lines = th_osm_sf,
  events = ra_sf,
  time_field = "days_since_start_of_year",
  w = rep(1, nrow(ra_sf)),
  kernel_name = "quartic",
  method = "simple",
  diggle_correction = FALSE,
  study_area = NULL,
  max_depth = 10,
  digits = 2,
  tol = 0.1,
  agg = 5,
  sparse=TRUE,
  grid_shape=c(5,5),
  sub_sample=1,
  verbose = TRUE,
  check = TRUE)
```
CV results are exported for ease of rendering.

```{r}
# # Export output object and read it in to minimize rendering time
# write_rds(tnkde_cv_scores, 'data/output/tnkde_cv_scores.rds') # Uncomment when running the CV again

# Read in output object
tnkde_cv_scores <- read_rds('data/output/tnkde_cv_scores.rds')
```


```{r}
knitr::kable(tnkde_cv_scores)
```

With this in mind, 

### 3.2.2 Performing TNKDE


```{r}
#| eval: false # eval: false
tnkde_densities <- tnkde(lines = th_osm_sf,
                   events = ra_sf,
                   time_field = "days_since_start_of_year",
                   w = rep(1, nrow(ra_sf)), 
                   samples_loc = sample_points,
                   samples_time = sample_time, 
                   kernel_name = "quartic",
                   bw_net = 700, bw_time = 100,
                   adaptive = TRUE,
                   trim_bw_net = 900,
                   trim_bw_time = 80,
                   method = "simple",
                   div = "bw", max_depth = 8,
                   digits = 2, tol = 0.1,
                   agg = 5, 
                   grid_shape = c(5,5), 
                   verbose  = TRUE)

```



## 3.3 Network Constrained G- and K-Function Analysis


### 3.3.1 Overall Analysis

```{r}
#| eval: false # eval: false
kfun_accidents_th <- kfunctions(th_osm_sf, 
                             ra_sf,
                             start = 0, 
                             end = 200, 
                             step = 50, 
                             width = 50, 
                             nsim = 49, 
                             # resolution = 100,
                             verbose = TRUE,
                             agg = 200,
                             conf_int = 0.05)
```

Results are saved for ease of rendering

```{r}
# # Export output object and read it in to minimize rendering time
# write_rds(kfun_accidents_th, 'data/output/th_kfun.rds') # Uncomment when running the Kfunction again

# Read in output object
kfun_accidents_th <- read_rds('data/output/th_kfun.rds')
```



```{r}
kfun_accidents_th$plotk
```

```{r}
kfun_accidents_th$plotg
```

From adsdaadsasd

### 3.3.2 Behavioral Factors

# 4 Conclusion
